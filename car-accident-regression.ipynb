{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5793796,"sourceType":"datasetVersion","datasetId":199387}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸš— Project Summary: Predicting Daily Car Accidents\n\n**Our project is to build a linear regression model to predict how many car accidents happen on a given day based on date-related and weather-related features.**\n\n ","metadata":{}},{"cell_type":"markdown","source":"<a id=\"p1\"></a>\n# 1.  Importing Packages\nWe use the same modules as we would use for any problem working with data. We have numpy and pandas to work with numbers and data, and we have seaborn and matplotlib to visualize data. We would also like to filter out unnecessary warnings.","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport holidays\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nsns.set(style=\"whitegrid\")\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:26:24.466727Z","iopub.execute_input":"2025-04-25T18:26:24.467022Z","iopub.status.idle":"2025-04-25T18:26:24.476526Z","shell.execute_reply.started":"2025-04-25T18:26:24.466997Z","shell.execute_reply":"2025-04-25T18:26:24.475038Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id=\"p2\"></a>\n# 2. Loading and Inspecting Data\nWith various Pandas functions, we load our training and test data set as well as inspect it to get an idea of the data we're working with. Wow! That is a large data set; just take a look at its shape. We're going to have to understand our data before modelling. ","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/us-accidents/US_Accidents_March23.csv')\n\n\n ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:26:32.534384Z","iopub.execute_input":"2025-04-25T18:26:32.534715Z","iopub.status.idle":"2025-04-25T18:28:48.603980Z","shell.execute_reply.started":"2025-04-25T18:26:32.534692Z","shell.execute_reply":"2025-04-25T18:28:48.602989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T11:11:53.715530Z","iopub.execute_input":"2025-04-25T11:11:53.715903Z","iopub.status.idle":"2025-04-25T11:11:53.724116Z","shell.execute_reply.started":"2025-04-25T11:11:53.715868Z","shell.execute_reply":"2025-04-25T11:11:53.722833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.describe()\nprint(train_df['Source'].value_counts().sort_index())\nmy_df = train_df[train_df['Source'] == train_df['Source'].value_counts().idxmax()].reset_index(drop=True)\nmy_df.shape\n# releases resources of unused data frames, Kaggle notebookes are limited to ~30GB \n#del train_df\n#gc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:29:05.838257Z","iopub.execute_input":"2025-04-25T18:29:05.840055Z","iopub.status.idle":"2025-04-25T18:29:17.065732Z","shell.execute_reply.started":"2025-04-25T18:29:05.840003Z","shell.execute_reply":"2025-04-25T18:29:17.064787Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a id=\"p2\"></a>\n# 2.CLEAN DATA\n","metadata":{}},{"cell_type":"code","source":"my_df['Temperature(C)'] = (my_df['Temperature(F)'] - 32) * 5.0 / 9.0\nbins = [-50, -20, -10, 0, 10, 20, 30, 40, 50, float('inf')]\nlabels = ['< -20Â°C', '-20â€“-10Â°C', '-10â€“0Â°C', '0â€“10Â°C', '10â€“20Â°C', '20â€“30Â°C', '30â€“40Â°C', '40â€“50Â°C', '50+Â°C']\nmy_df['Temperature_Range'] = pd.cut(my_df['Temperature(C)'], bins=bins, labels=labels, right=False)\nprint (my_df['Temperature_Range'].value_counts().sort_index())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:30:16.370390Z","iopub.execute_input":"2025-04-25T18:30:16.370769Z","iopub.status.idle":"2025-04-25T18:30:16.564994Z","shell.execute_reply.started":"2025-04-25T18:30:16.370741Z","shell.execute_reply":"2025-04-25T18:30:16.564006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"temp_ranges = {\n    \"< -20Â°C\": -20,\n    \"-20â€“-10Â°C\": -15,\n    \"-10â€“0Â°C\": -5,\n    \"0â€“10Â°C\": 5,\n    \"10â€“20Â°C\": 15,\n    \"20â€“30Â°C\": 25,\n    \"30â€“40Â°C\": 35,\n    \"40â€“50Â°C\": 45,\n    \"50+Â°C\": 50\n}\n\n# Assuming 'Temperature_Range' is a column in your dataset\n# Map temperature ranges to their midpoint values\nmy_df['Temperature_Midpoint'] = my_df['Temperature_Range'].map(temp_ranges)\nmy_df = pd.get_dummies(my_df, columns=['Temperature_Range'], prefix='Temp_Range')\n\n# Now you can use the new one-hot encoded columns in your linear regression model\nmy_df[['Temp_Range_< -20Â°C', 'Temp_Range_-20â€“-10Â°C', 'Temp_Range_-10â€“0Â°C', \n           'Temp_Range_0â€“10Â°C', 'Temp_Range_10â€“20Â°C', 'Temp_Range_20â€“30Â°C', \n           'Temp_Range_30â€“40Â°C', 'Temp_Range_40â€“50Â°C', 'Temp_Range_50+Â°C']] \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T21:15:12.792682Z","iopub.execute_input":"2025-04-25T21:15:12.793023Z","iopub.status.idle":"2025-04-25T21:15:29.197700Z","shell.execute_reply.started":"2025-04-25T21:15:12.792999Z","shell.execute_reply":"2025-04-25T21:15:29.196422Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"my_df['Wind_Chill(C)'] = (my_df['Wind_Chill(F)'] - 32) * 5.0 / 9.0\nmy_df = my_df.drop(['Wind_Chill(F)'], axis=1)\nbins = [-50, -20, -10, 0, 10, 20, 30, 40, 50, float('inf')]\nlabels = ['< -20Â°C', '-20â€“-10Â°C', '-10â€“0Â°C', '0â€“10Â°C', '10â€“20Â°C', '20â€“30Â°C', '30â€“40Â°C', '40â€“50Â°C', '50+Â°C']\nmy_df['Wind_Chill_Range'] = pd.cut(my_df['Wind_Chill(C)'], bins=bins, labels=labels, right=False)\nprint (my_df['Wind_Chill_Range'].value_counts().sort_index())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T21:04:44.927961Z","iopub.execute_input":"2025-04-25T21:04:44.928309Z","iopub.status.idle":"2025-04-25T21:05:00.623338Z","shell.execute_reply.started":"2025-04-25T21:04:44.928286Z","shell.execute_reply":"2025-04-25T21:05:00.622307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Create bins and labels for Humidity range\nhumidity_bins = [0, 20, 40, 60, 80, 100]\nhumidity_labels = ['0-20%', '21-40%', '41-60%', '61-80%', '81-100%']\nmy_df['Humidity_Range'] = pd.cut(my_df['Humidity(%)'], bins=humidity_bins, labels=humidity_labels, include_lowest=True)\n\n# Count the number of records in each humidity range\nhumidity_range_counts = my_df['Humidity_Range'].value_counts().sort_index()\n\n# Display the counts of the Humidity_Range column\nprint(\"Humidity Range Counts:\")\nprint(humidity_range_counts)\n\nmy_df_encoded = pd.get_dummies(my_df, columns=['Humidity_Range'], drop_first=True)\n\n# Now 'my_df_encoded' will have columns like:\n# 'Humidity_Range_21-40%', 'Humidity_Range_41-60%', 'Humidity_Range_61-80%', 'Humidity_Range_81-100%'\n\nprint(my_df_encoded.head())\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T21:48:26.701802Z","iopub.execute_input":"2025-04-25T21:48:26.702742Z","iopub.status.idle":"2025-04-25T21:48:42.510983Z","shell.execute_reply.started":"2025-04-25T21:48:26.702711Z","shell.execute_reply":"2025-04-25T21:48:42.510095Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define bins and labels for Visibility ranges\nvisibility_bins = [0, 1, 3, 5, 10, 20, float('inf')]\nvisibility_labels = ['0-1 mi', '1-3 mi', '3-5 mi', '5-10 mi', '10-20 mi', '20+ mi']\n\n# Bin the Visibility(mi) values\nmy_df['Visibility_Range'] = pd.cut(my_df['Visibility(mi)'], bins=visibility_bins, labels=visibility_labels, include_lowest=True)\n\n# Count the number of records in each range\nvisibility_counts = my_df['Visibility_Range'].value_counts().sort_index()\n\n# Display the result\nprint(\"Visibility Range Counts:\")\nprint(visibility_counts)\n\nvisibility_bins = [0, 1, 3, 5, 10, 20, float('inf')]\nvisibility_labels = ['0-1 mi', '1-3 mi', '3-5 mi', '5-10 mi', '10-20 mi', '20+ mi']\nmy_df['Visibility_Range'] = pd.cut(my_df['Visibility(mi)'], bins=visibility_bins, labels=visibility_labels, right=False)\nvisibility_dummies = pd.get_dummies(my_df['Visibility_Range'], prefix='Visibility')\nmy_df = pd.concat([my_df, visibility_dummies], axis=1)\nmy_df = my_df.drop(['Visibility_Range'], axis=1)\nprint(my_df.head())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T22:07:42.739720Z","iopub.execute_input":"2025-04-25T22:07:42.740099Z","iopub.status.idle":"2025-04-25T22:08:00.261230Z","shell.execute_reply.started":"2025-04-25T22:07:42.740072Z","shell.execute_reply":"2025-04-25T22:08:00.260217Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(my_df['Distance(mi)'].value_counts().sort_index())\n\nmy_df['Distance(km)'] = my_df['Distance(mi)'] * 1.60934\nbins_km = [0, 5, 10, 25, 50, float('inf')]\nlabels_km = ['0â€“5 km', '5-10 km', '10â€“25 km', '25-50 km', '50+ km']\nmy_df['Distance_Range'] = pd.cut(my_df['Distance(km)'], bins=bins_km, labels=labels_km, right=False)\nprint(my_df['Distance_Range'].value_counts().sort_index())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:30:19.352567Z","iopub.execute_input":"2025-04-25T18:30:19.353997Z","iopub.status.idle":"2025-04-25T18:30:19.613803Z","shell.execute_reply.started":"2025-04-25T18:30:19.353962Z","shell.execute_reply":"2025-04-25T18:30:19.612672Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(my_df['Precipitation(in)'].value_counts().sort_index())\nmy_df['Precipitation_Flag'] = my_df['Precipitation(in)'] > 0\nprint(my_df['Precipitation_Flag'].value_counts().sort_index())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:30:23.121855Z","iopub.execute_input":"2025-04-25T18:30:23.122303Z","iopub.status.idle":"2025-04-25T18:30:23.204449Z","shell.execute_reply.started":"2025-04-25T18:30:23.122272Z","shell.execute_reply":"2025-04-25T18:30:23.203013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(my_df['Weather_Condition'].unique())\nmy_df.loc[my_df['Weather_Condition'].str.contains('Rain', case=False, na=False), 'Weather_Simplified'] = 'Rain'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Precipitation', case=False, na=False), 'Weather_Simplified'] = 'Rain'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Drizzle', case=False, na=False), 'Weather_Simplified'] = 'Rain'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Thunder', case=False, na=False), 'Weather_Simplified'] = 'Thunder'\nmy_df.loc[my_df['Weather_Condition'].str.contains('T-Storm', case=False, na=False), 'Weather_Simplified'] = 'Thunder'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Snow', case=False, na=False), 'Weather_Simplified'] = 'Snow'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Sleet', case=False, na=False), 'Weather_Simplified'] = 'Snow'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Hail', case=False, na=False), 'Weather_Simplified'] = 'Snow'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Ice', case=False, na=False), 'Weather_Simplified'] = 'Snow'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Cloud', case=False, na=False), 'Weather_Simplified'] = 'Cloudy'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Overcast', case=False, na=False), 'Weather_Simplified'] = 'Cloudy'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Fog', case=False, na=False), 'Weather_Simplified'] = 'Fog'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Haze', case=False, na=False), 'Weather_Simplified'] = 'Fog'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Mist', case=False, na=False), 'Weather_Simplified'] = 'Fog'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Dust', case=False, na=False), 'Weather_Simplified'] = 'Dust'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Sand', case=False, na=False), 'Weather_Simplified'] = 'Dust'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Smoke', case=False, na=False), 'Weather_Simplified'] = 'Smoke'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Fair', case=False, na=False), 'Weather_Simplified'] = 'Fair'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Wintry', case=False, na=False), 'Weather_Simplified'] = 'Wintry'\nmy_df.loc[my_df['Weather_Condition'].str.contains('Squalls', case=False, na=False), 'Weather_Simplified'] = 'Squalls'\n\nprint(my_df['Weather_Simplified'].value_counts().head(20))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:30:28.092989Z","iopub.execute_input":"2025-04-25T18:30:28.093462Z","iopub.status.idle":"2025-04-25T18:31:08.257198Z","shell.execute_reply.started":"2025-04-25T18:30:28.093430Z","shell.execute_reply":"2025-04-25T18:31:08.256158Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"my_df['Start_Time'] = pd.to_datetime(my_df['Start_Time'], errors='coerce')\nprint(\"Total rows : \", my_df.shape[0])\nprint(\"Valid rows : \", my_df[my_df['Start_Time'].notna()].shape[0])\nmy_df = my_df[my_df['Start_Time'].notna()]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:31:20.975058Z","iopub.execute_input":"2025-04-25T18:31:20.975358Z","iopub.status.idle":"2025-04-25T18:31:26.397553Z","shell.execute_reply.started":"2025-04-25T18:31:20.975338Z","shell.execute_reply":"2025-04-25T18:31:26.396553Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <a id=\"p2\"></a>\n# 3. EDA","metadata":{}},{"cell_type":"markdown","source":"Accidents per day:\n\nGroup by date and count accidents.\n\nPlot a time series to check trends (e.g., increasing/decreasing).\n","metadata":{}},{"cell_type":"code","source":"my_df['Start_Time'] = pd.to_datetime(my_df['Start_Time'])\n\n# Extract just the date part (without time)\nmy_df['Date'] = my_df['Start_Time'].dt.date\n\n# Group by date and count the number of accidents\naccidents_per_day = my_df.groupby('Date').size().reset_index(name='accident_count')\n\n# Convert 'Date' back to datetime for proper plotting\naccidents_per_day['Date'] = pd.to_datetime(accidents_per_day['Date'])\n\n# Plot the time series\nplt.figure(figsize=(15, 6))\nsns.lineplot(data=accidents_per_day, x='Date', y='accident_count')\nplt.title(\"Accidents Per Day\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Number of Accidents\")\nplt.grid(True)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:31:31.532477Z","iopub.execute_input":"2025-04-25T18:31:31.533382Z","iopub.status.idle":"2025-04-25T18:31:33.953677Z","shell.execute_reply.started":"2025-04-25T18:31:31.533338Z","shell.execute_reply":"2025-04-25T18:31:33.952551Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Day of week effects:\n\nAre weekends more dangerous than weekdays?","metadata":{}},{"cell_type":"code","source":"my_df['Start_Time'] = pd.to_datetime(my_df['Start_Time'])\n\n# Extract day of the week (0=Monday, 6=Sunday)\nmy_df['DayOfWeek'] = my_df['Start_Time'].dt.dayofweek\nmy_df['DayName'] = my_df['Start_Time'].dt.day_name()\n\n# Group by day name and count number of accidents\naccidents_by_day = my_df['DayName'].value_counts().reindex([\n    'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'\n])\n\n# Plot the result\nplt.figure(figsize=(10, 6))\nsns.barplot(x=accidents_by_day.index, y=accidents_by_day.values, palette='viridis')\nplt.title(\"Total Accidents by Day of the Week\")\nplt.xlabel(\"Day of Week\")\nplt.ylabel(\"Number of Accidents\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:31:52.006677Z","iopub.execute_input":"2025-04-25T18:31:52.007095Z","iopub.status.idle":"2025-04-25T18:31:54.076544Z","shell.execute_reply.started":"2025-04-25T18:31:52.007071Z","shell.execute_reply":"2025-04-25T18:31:54.073984Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"What time are most accidents happening? (Rush hours?)","metadata":{}},{"cell_type":"code","source":"\n# Convert to datetime if not already\nmy_df['Start_Time'] = pd.to_datetime(my_df['Start_Time'])\n\n# Extract the hour of the day (0 to 23)\nmy_df['Hour'] = my_df['Start_Time'].dt.hour\n\n# Count accidents by hour\naccidents_by_hour = my_df['Hour'].value_counts().sort_index()\n\n# Plotting\nplt.figure(figsize=(12, 6))\nsns.barplot(x=accidents_by_hour.index, y=accidents_by_hour.values, palette='rocket')\nplt.title(\"Accidents by Hour of the Day\")\nplt.xlabel(\"Hour (24-hour format)\")\nplt.ylabel(\"Number of Accidents\")\nplt.xticks(range(0, 24))\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:32:05.416504Z","iopub.execute_input":"2025-04-25T18:32:05.417243Z","iopub.status.idle":"2025-04-25T18:32:06.112190Z","shell.execute_reply.started":"2025-04-25T18:32:05.417211Z","shell.execute_reply":"2025-04-25T18:32:06.111197Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nsuggestion is to create  a new feature: rush_hour = (7â€“8 AM or 4â€“6 PM)","metadata":{}},{"cell_type":"markdown","source":"Do winter months see more accidents?","metadata":{}},{"cell_type":"code","source":"my_df['Start_Time'] = pd.to_datetime(my_df['Start_Time'])\n\n# Extract month and month name\nmy_df['Month'] = my_df['Start_Time'].dt.month\nmy_df['MonthName'] = my_df['Start_Time'].dt.month_name()\n\n# Group by month name\naccidents_by_month = my_df['MonthName'].value_counts().reindex([\n    'January', 'February', 'March', 'April', 'May', 'June',\n    'July', 'August', 'September', 'October', 'November', 'December'\n])\n\n# Plot\nplt.figure(figsize=(12, 6))\nsns.barplot(x=accidents_by_month.index, y=accidents_by_month.values, palette='coolwarm')\nplt.title(\"Accidents by Month\")\nplt.xlabel(\"Month\")\nplt.ylabel(\"Number of Accidents\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n\nprint(accidents_by_month)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T21:22:31.402751Z","iopub.execute_input":"2025-04-25T21:22:31.403143Z","iopub.status.idle":"2025-04-25T21:22:33.859406Z","shell.execute_reply.started":"2025-04-25T21:22:31.403120Z","shell.execute_reply":"2025-04-25T21:22:33.858225Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Correlation between each weather condition and accident count.\n\nAccident rate by weather condition:\n\nMore accidents during rainy or snowy days?","metadata":{}},{"cell_type":"code","source":"weather_counts = my_df['Weather_Simplified'].value_counts()\nmy_df['Weather_Simple'] = my_df['Weather_Simplified'].str.lower()\n# Define weather keywords\ndef simplify_weather(condition):\n    if pd.isna(condition): return 'Unknown'\n    if 'rain' in condition: return 'Rain'\n    if 'snow' in condition: return 'Snow'\n    if 'Dust' in condition: return 'Dust'\n    if 'fog' in condition or 'haze' in condition: return 'Fog'\n    if 'storm' in condition or 'thunder' in condition: return 'Storm'\n    if 'clear' in condition: return 'Clear'\n    if 'cloud' in condition: return 'Cloudy'\n    return 'Other'\n\nmy_df['Weather_Grouped'] = my_df['Weather_Simple'].apply(simplify_weather)\n\naccidents_by_weather = my_df['Weather_Grouped'].value_counts()\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x=accidents_by_weather.index, y=accidents_by_weather.values, palette=\"coolwarm\")\nplt.title(\"Accident Count by Simplified Weather Condition\")\nplt.xlabel(\"Weather Condition\")\nplt.ylabel(\"Number of Accidents\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:32:18.522017Z","iopub.execute_input":"2025-04-25T18:32:18.522356Z","iopub.status.idle":"2025-04-25T18:32:22.486395Z","shell.execute_reply.started":"2025-04-25T18:32:18.522333Z","shell.execute_reply":"2025-04-25T18:32:22.485255Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Do more accidents happen near traffic signals?\n\nDoes this rate change by:\n\nTime of day? (e.g., are intersections more dangerous during rush hours?)\n\nWeather? (e.g., rain + traffic light = more accidents?)\n\nIs there a correlation between traffic signals and accident severity or distance?","metadata":{}},{"cell_type":"code","source":"signal_counts = my_df['Traffic_Signal'].value_counts()\n\n# Bar plot\nplt.figure(figsize=(6,4))\nsns.barplot(x=signal_counts.index, y=signal_counts.values, palette='viridis')\nplt.xticks([0,1], ['No Traffic Signal', 'Traffic Signal'])\nplt.ylabel(\"Accident Count\")\nplt.title(\"Accidents With vs Without Traffic Signals\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:32:27.676081Z","iopub.execute_input":"2025-04-25T18:32:27.676419Z","iopub.status.idle":"2025-04-25T18:32:27.935415Z","shell.execute_reply.started":"2025-04-25T18:32:27.676396Z","shell.execute_reply":"2025-04-25T18:32:27.934345Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nDoes this rate change by time of day?","metadata":{}},{"cell_type":"code","source":"# Extract hour\nmy_df['Hour'] = pd.to_datetime(my_df['Start_Time']).dt.hour\n\n# Group by hour and calculate traffic signal rate\nhourly_signal_rate = my_df.groupby('Hour')['Traffic_Signal'].mean()\n\n# Plot\nplt.figure(figsize=(10,5))\nsns.lineplot(x=hourly_signal_rate.index, y=hourly_signal_rate.values, marker='o')\nplt.title(\"Traffic Signal Accident Rate by Hour\")\nplt.xlabel(\"Hour of Day\")\nplt.ylabel(\"Proportion of Accidents Near Traffic Signals\")\nplt.xticks(range(0, 24))\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:32:31.277742Z","iopub.execute_input":"2025-04-25T18:32:31.278094Z","iopub.status.idle":"2025-04-25T18:32:32.141912Z","shell.execute_reply.started":"2025-04-25T18:32:31.278069Z","shell.execute_reply":"2025-04-25T18:32:32.140681Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nDoes this rate change by weather condition?","metadata":{}},{"cell_type":"code","source":"def simplify_weather(condition):\n    if pd.isna(condition): return 'Unknown'\n    cond = condition.lower()\n    if 'rain' in cond: return 'Rain'\n    if 'snow' in cond: return 'Snow'\n    if 'fog' in cond or 'haze' in cond: return 'Fog'\n    if 'storm' in cond or 'thunder' in cond: return 'Storm'\n    if 'clear' in cond: return 'Clear'\n    if 'cloud' in cond: return 'Cloudy'\n    return 'Other'\n\nmy_df['Weather_Grouped'] = my_df['Weather_Condition'].apply(simplify_weather)\n\nweather_signal_rate = my_df.groupby('Weather_Grouped')['Traffic_Signal'].mean().sort_values(ascending=False)\n\n# Plot\nplt.figure(figsize=(10,5))\nsns.barplot(x=weather_signal_rate.index, y=weather_signal_rate.values, palette=\"coolwarm\")\nplt.title(\"Traffic Signal Rate by Weather Condition\")\nplt.ylabel(\"Proportion of Accidents Near Traffic Signals\")\nplt.xlabel(\"Weather\")\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:32:44.460562Z","iopub.execute_input":"2025-04-25T18:32:44.461401Z","iopub.status.idle":"2025-04-25T18:32:47.851401Z","shell.execute_reply.started":"2025-04-25T18:32:44.461376Z","shell.execute_reply":"2025-04-25T18:32:47.850419Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nAre accidents more likely to occur near stations?\n\nIs this rate higher in urban vs. rural areas?\n\nDo high station rates correlate with shorter travel distances or less severity?","metadata":{}},{"cell_type":"code","source":"station_counts = my_df['Station'].value_counts()\n\n# Bar plot\nplt.figure(figsize=(6,4))\nsns.barplot(x=station_counts.index, y=station_counts.values, palette='crest')\nplt.xticks([0,1], ['No Station Nearby', 'Station Nearby'])\nplt.ylabel(\"Accident Count\")\nplt.title(\"Accidents Near Stations vs Not\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:32:57.535157Z","iopub.execute_input":"2025-04-25T18:32:57.535459Z","iopub.status.idle":"2025-04-25T18:32:57.782901Z","shell.execute_reply.started":"2025-04-25T18:32:57.535438Z","shell.execute_reply":"2025-04-25T18:32:57.781959Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\nCorrelation between traffic signal and severity / distance","metadata":{}},{"cell_type":"code","source":"correlations = my_df[['Traffic_Signal', 'Severity', 'Distance(mi)']].corr()\n\nplt.figure(figsize=(5,4))\nsns.heatmap(correlations, annot=True, cmap='coolwarm')\nplt.title(\"Correlation Matrix: Traffic Signal, Severity, Distance\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:33:01.346826Z","iopub.execute_input":"2025-04-25T18:33:01.347191Z","iopub.status.idle":"2025-04-25T18:33:01.824146Z","shell.execute_reply.started":"2025-04-25T18:33:01.347165Z","shell.execute_reply":"2025-04-25T18:33:01.823121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(8,5))\nsns.scatterplot(data=my_df, x='Distance(mi)', y='Severity', alpha=0.4)\nplt.title(\"Scatter Plot: Distance vs Severity\")\nplt.xlabel(\"Distance (miles)\")\nplt.ylabel(\"Severity\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:33:04.387601Z","iopub.execute_input":"2025-04-25T18:33:04.387955Z","iopub.status.idle":"2025-04-25T18:33:12.905288Z","shell.execute_reply.started":"2025-04-25T18:33:04.387933Z","shell.execute_reply":"2025-04-25T18:33:12.904328Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"correlation = my_df['Distance(mi)'].corr(my_df['Severity'])\nprint(f\"Correlation between Distance and Severity: {correlation:.3f}\")\nsns.lmplot(data=my_df, x='Distance(mi)', y='Severity', line_kws={\"color\": \"red\"})\nplt.title(\"Distance vs Severity with Regression Line\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T18:33:16.689714Z","iopub.execute_input":"2025-04-25T18:33:16.690482Z","iopub.status.idle":"2025-04-25T18:36:55.435480Z","shell.execute_reply.started":"2025-04-25T18:33:16.690453Z","shell.execute_reply":"2025-04-25T18:36:55.433829Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Conclusion.It seems to be a very weak correlation between severity and distance\nIn our dataset, accident distance and severity are mostly unrelated. A long accident zone doesn't necessarily mean it's more or less severe.","metadata":{}},{"cell_type":"code","source":"severity_counts = my_df['Severity'].value_counts().sort_index() \nplt.figure(figsize=(8,5))\nsns.barplot(x=severity_counts.index, y=severity_counts.values, palette='viridis')\nplt.title(\"Accident Count by Severity Level\")\nplt.xlabel(\"Severity\")\nplt.ylabel(\"Number of Accidents\")\nplt.xticks(ticks=[0,1,2,3], labels=['1 (Low)', '2', '3', '4 (High)'])  # optional pretty labels\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T11:16:57.044586Z","iopub.status.idle":"2025-04-25T11:16:57.044893Z","shell.execute_reply.started":"2025-04-25T11:16:57.044753Z","shell.execute_reply":"2025-04-25T11:16:57.044765Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"my_df['Date'] = pd.to_datetime( my_df['Start_Time']).dt.date\ndaily_severity = my_df.groupby(['Date', 'Severity']).size().reset_index(name='Accident_Count')\npivot_df = daily_severity.pivot(index='Date', columns='Severity', values='Accident_Count').fillna(0)\npivot_df.plot(figsize=(12,6))\nplt.title(\"Daily Accident Count by Severity Level\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"Number of Accidents\")\nplt.legend(title=\"Severity\")\nplt.tight_layout()\nplt.show()\n\n\n#pivot_df = daily_severity.pivot(index='Date', columns='Severity', values='Accident_Count').fillna(0)\n#pivot_df.plot(kind='area', stacked=True, figsize=(12,6), colormap='viridis')\n#plt.title(\"Daily Accident Count by Severity Level\")\n#plt.xlabel(\"Date\")\n#plt.ylabel(\"Number of Accidents\")\n#plt.legend(title=\"Severity\")\n#plt.tight_layout()\n#plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T21:34:35.188585Z","iopub.execute_input":"2025-04-25T21:34:35.188950Z","iopub.status.idle":"2025-04-25T21:34:37.628260Z","shell.execute_reply.started":"2025-04-25T21:34:35.188926Z","shell.execute_reply":"2025-04-25T21:34:37.627362Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We want to measure the correlation between accident count and severity","metadata":{}},{"cell_type":"code","source":"my_df['Date'] = pd.to_datetime(my_df['Start_Time']).dt.date\n\n# Group by Date and calculate accident count and average severity\n\ndaily_stats = my_df.groupby('Date').agg(\n    accident_count=pd.NamedAgg(column='Severity', aggfunc='size'),\n    avg_severity=pd.NamedAgg(column='Severity', aggfunc='mean')\n).reset_index()\n\n\nprint(daily_stats.head())\ncorrelation = daily_stats['accident_count'].corr(daily_stats['avg_severity'])\nprint(f\"Correlation between accident count and average severity: {correlation:.3f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T21:34:42.810822Z","iopub.execute_input":"2025-04-25T21:34:42.811780Z","iopub.status.idle":"2025-04-25T21:34:44.561809Z","shell.execute_reply.started":"2025-04-25T21:34:42.811750Z","shell.execute_reply":"2025-04-25T21:34:44.560967Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We are building a model to predict the number of accidents per day and we are wondering whether to include:\n\n1. Severity (average severity of accidents on that day)\n\n2. Distance(mi) (average distance of accidents on that day)\n\n\n-0.486 suggests that there is a moderate negative correlation between accident count and severity.\nMore accidents tend to correlate with lower severity, but the relationship is not very strong.\n\nSo,it seems, that Severity is not a cause of accident count â€” it's more like a result or outcome of an accident.\nIncluding average severity per day as a feature to predict accident count per day would create a causal confusion. And should not be taken as feature.","metadata":{}},{"cell_type":"code","source":"my_df[['Temperature(C)', 'Humidity(%)', 'Wind_Chill(C)']].describe()\nmy_df[['Temperature(C)', 'Humidity(%)', 'Wind_Chill(C)']].isna().mean()\nfor col in ['Temperature(C)', 'Humidity(%)', 'Wind_Chill(C)']:\n    sns.histplot(my_df[col], kde=True)\n    plt.title(f'Distribution of {col}')\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T21:35:08.585199Z","iopub.execute_input":"2025-04-25T21:35:08.585495Z","iopub.status.idle":"2025-04-25T21:36:00.053877Z","shell.execute_reply.started":"2025-04-25T21:35:08.585474Z","shell.execute_reply":"2025-04-25T21:36:00.052699Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"my_df['Start_Time'] = pd.to_datetime(my_df['Start_Time'])\nmy_df['date'] = my_df['Start_Time'].dt.date\n\ndaily_stats = my_df.groupby('date').agg({\n    'Temperature(C)': 'mean',\n    'Humidity(%)': 'mean',\n    'Wind_Chill(C)': 'mean',\n    'ID': 'count'  # or your accident ID\n}).rename(columns={'ID': 'accident_count'})\n\n\n\nsns.scatterplot(x='Temperature(C)', y='accident_count', data=daily_stats)\nplt.title('Accident Count vs Temperature')\nplt.show()\n\nsns.scatterplot(x='Humidity(%)', y='accident_count', data=daily_stats)\nplt.title('Accident Count vs Humidity')\nplt.show()\n\ndaily_stats.corr()['accident_count']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T21:37:21.179989Z","iopub.execute_input":"2025-04-25T21:37:21.180337Z","iopub.status.idle":"2025-04-25T21:37:23.670107Z","shell.execute_reply.started":"2025-04-25T21:37:21.180313Z","shell.execute_reply":"2025-04-25T21:37:23.669122Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ðŸ” Quick Recap of Correlations\n\n| **Feature**         | **Correlation with `accident_count`** | **Interpretation**                |\n|---------------------|----------------------------------------|------------------------------------|\n| Temperature (Â°C)     | `-0.023413`                                | Negligible correlation             |\n| Humidity (%)         | `+0.026`                                | Weak positive correlation          |\n| Wind Chill (Â°F)      | `0.177`                                | Negligible negative correlation    |\n","metadata":{}},{"cell_type":"code","source":"\n# Convert Start_Time to datetime and extract date\nmy_df['Start_Time'] = pd.to_datetime(my_df['Start_Time'])\nmy_df['date'] = my_df['Start_Time'].dt.date\n\n# Group by date to get daily accident count and most common Wind_Direction\ndaily_df = my_df.groupby('date').agg({\n    'Wind_Direction': lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown',\n    'ID': 'count'  # or len(x) if 'ID' is not available\n}).rename(columns={'ID': 'accident_count'}).reset_index()\n\n# Plotting\nplt.figure(figsize=(12, 6))\nsns.barplot(data=daily_df, x='Wind_Direction', y='accident_count', estimator='mean', ci=None)\nplt.xticks(rotation=45)\nplt.title('Average Daily Accident Count by Wind Direction')\nplt.xlabel('Wind Direction')\nplt.ylabel('Average Accident Count')\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T11:16:57.052300Z","iopub.status.idle":"2025-04-25T11:16:57.052621Z","shell.execute_reply.started":"2025-04-25T11:16:57.052443Z","shell.execute_reply":"2025-04-25T11:16:57.052454Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ensure Start_Time is datetime and extract date\nmy_df['Start_Time'] = pd.to_datetime(my_df['Start_Time'])\nmy_df['date'] = my_df['Start_Time'].dt.date\n\n# Group by date and calculate daily stats\ndaily_df = my_df.groupby('date').agg({\n    'ID': 'count',  # daily accident count\n    'Visibility(mi)': 'mean'  # average visibility\n}).rename(columns={'ID': 'accident_count'}).reset_index()\n\nprint(daily_df)\n\n# Plotting correlation\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=daily_df, x='Visibility(mi)', y='accident_count')\nsns.regplot(data=daily_df, x='Visibility(mi)', y='accident_count', scatter=False, color='red')\nplt.title('Visibility vs. Daily Accident Count')\nplt.xlabel('Average Daily Visibility (mi)')\nplt.ylabel('Accident Count')\nplt.tight_layout()\nplt.show()\n\n# Calculate and print correlation\ncorrelation = daily_df['Visibility(mi)'].corr(daily_df['accident_count'])\nprint(f\"Correlation between Visibility and Accident Count: {correlation:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T22:03:21.666107Z","iopub.execute_input":"2025-04-25T22:03:21.666531Z","iopub.status.idle":"2025-04-25T22:03:24.400135Z","shell.execute_reply.started":"2025-04-25T22:03:21.666503Z","shell.execute_reply":"2025-04-25T22:03:24.399128Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Make sure Start_Time is datetime and extract date\nmy_df['Start_Time'] = pd.to_datetime(my_df['Start_Time'])\nmy_df['date'] = my_df['Start_Time'].dt.date\n\n# Group by date to get daily average temperature and accident count\ndaily_df = my_df.groupby('date').agg({\n    'ID': 'count',  # number of accidents\n    'Temperature(C)': 'mean'  # average temperature\n}).rename(columns={'ID': 'accident_count'}).reset_index()\n\n# Plot: Temperature vs Accident Count\nplt.figure(figsize=(8, 6))\nsns.scatterplot(data=daily_df, x='Temperature(C)', y='accident_count')\nsns.regplot(data=daily_df, x='Temperature(C)', y='accident_count', scatter=False, color='red')\nplt.title('Temperature vs. Daily Accident Count')\nplt.xlabel('Average Daily Temperature (Â°C)')\nplt.ylabel('Accident Count')\nplt.tight_layout()\nplt.show()\n\n# Calculate correlation\ncorrelation = daily_df['Temperature(C)'].corr(daily_df['accident_count'])\nprint(f\"Correlation between Temperature and Accident Count: {correlation:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T11:16:57.056857Z","iopub.status.idle":"2025-04-25T11:16:57.057255Z","shell.execute_reply.started":"2025-04-25T11:16:57.057105Z","shell.execute_reply":"2025-04-25T11:16:57.057120Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Correlation Analysis: Temperature vs. Accident Count\n\n- **Correlation coefficient**: -0.023  \n- **Interpretation**: This is a **negligible** positive correlation, meaning changes in temperature have **almost no linear relationship** with the number of accidents reported per day.  \n- **Conclusion**: Temperature may **not be a strong predictive feature** for modeling daily accident counts using linear regression.\n","metadata":{}},{"cell_type":"markdown","source":"A correlation of â€“0.006 between Visibility and Accident Count indicates a negligible (almost zero) linear relationship","metadata":{}},{"cell_type":"code","source":"\n# Step 1: Create a binary flag for precipitation\nmy_df['Precipitation_Flag'] = my_df['Precipitation(in)'] > 0\ndaily_accidents = my_df.groupby(['Date', 'Precipitation_Flag']).size().reset_index(name='accident_count')\navg_accidents = daily_accidents.groupby('Precipitation_Flag')['accident_count'].mean().reset_index()\ncorrelation = daily_accidents['Precipitation_Flag'].corr(daily_accidents['accident_count'])\n\n# Step 2: Group by Precipitation Flag and calculate average accident count\n#avg_accidents = my_df.groupby('Precipitation_Flag')['accident_count'].mean().reset_index()\n\n# Step 3: Plot\nsns.barplot(data=avg_accidents, x='Precipitation_Flag', y='accident_count')\nplt.xticks([0, 1], ['No Precipitation', 'Precipitation'])\nplt.title('Average Daily Accident Count by Precipitation')\nplt.xlabel('Precipitation')\nplt.ylabel('Average Accident Count')\nplt.show()\nprint(f\"Correlation between Precipitation and Accident Count: {correlation:.3f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T11:21:10.622707Z","iopub.execute_input":"2025-04-25T11:21:10.623065Z","iopub.status.idle":"2025-04-25T11:21:11.256392Z","shell.execute_reply.started":"2025-04-25T11:21:10.623041Z","shell.execute_reply":"2025-04-25T11:21:11.255437Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I might think more rain or snow = more accidents, but the negative correlation in ×¦×˜ dataset suggests the opposite: fewer accidents when thereâ€™s more precipitation.\n\nWhen itâ€™s raining, snowing, or the weather is bad:\n\nDrivers slow down, are more alert, and drive more cautiously.\n\nSome people might choose not to drive at all during heavy precipitation.\n\nSo paradoxically, bad weather might reduce accident frequency due to increased caution.\n\nAccidents tend to happen more when:\n\nRoads are dry and people feel safe.\n\nHigher traffic volume, such as during rush hours or weekends with good weather.\n\nThat increased activity can raise the chance of accidents â€” even if conditions are \"perfect.\"","metadata":{}},{"cell_type":"markdown","source":"### <a id=\"p2\"></a>\n\n# 3. Extracting Start_Time and Sunrise_Sunset\n\nWe start by extracting some useful time-based features from the `Start_Time` column and a flag based on the `Sunrise_Sunset` column: \n\n\n\n","metadata":{}},{"cell_type":"code","source":"my_df['Date'] = my_df['Start_Time'].dt.normalize()\nmy_df['Weekday'] = my_df['Start_Time'].dt.weekday\nmy_df['day_of_week'] = my_df['Start_Time'].dt.dayofweek\nmy_df['Weekday_Name'] = my_df['Start_Time'].dt.day_name()\nmy_df['Hour'] = my_df['Start_Time'].dt.hour\nmy_df['Month'] = my_df['Start_Time'].dt.month\nmy_df['Month_Name'] = my_df['Start_Time'].dt.month_name()\nmy_df['Is_Weekend'] = my_df['Weekday'].isin([5,6]).astype(bool)\nmy_df['Is_Night'] = my_df['Sunrise_Sunset'].map({'Night': 1, 'Day': 0}).astype(bool)\n\nus_holidays = holidays.US()\nmy_df['Is_Holiday'] = my_df['Start_Time'].isin(us_holidays).astype(int)\ndef is_rush_hour(hour, weekday):    \n    hour, weekday = int(hour), int(weekday)\n    if weekday < 5:\n        return (7 <= hour <= 9) or (16 <= hour <= 18)\n    else:\n        return (11 <= hour <= 13) or (17 <= hour <= 19)\n\nmy_df['Is_Rush_Hour'] = my_df.apply(lambda row: is_rush_hour(row['Hour'], row['Weekday']), axis=1)\n\nmy_df['Is_Rush_Hour_Weekday'] = ((my_df['Is_Rush_Hour'] == 1) & (my_df['Is_Weekend'] == 0)).astype(int)\nmy_df['Is_Rush_Hour_Weekend'] = ((my_df['Is_Rush_Hour'] == 1) & (my_df['Is_Weekend'] == 1)).astype(int)\npeak_hours = [13, 14, 15, 16, 17]\nmy_df['Is_Peak_Hour'] = my_df['Hour'].isin(peak_hours).astype(int)\n\ndef get_hour_risk_level(hour):\n    if hour in [13, 14, 15, 16, 17, 18]:\n        return 'High'\n    elif hour in [6, 7, 8, 9, 10, 11, 12, 19]:\n        return 'Medium'\n    else:\n        return 'Low'\n\nmy_df['Hour_Risk_Level'] = my_df['Hour'].apply(get_hour_risk_level)\n\nmy_df[['Month', 'Is_Weekend', 'Date', 'Start_Time', 'day_of_week','Is_Night','Is_Holiday','Is_Rush_Hour_Weekday','Is_Rush_Hour_Weekend','Is_Peak_Hour','Hour_Risk_Level']]\n#my_df.head(20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T19:42:27.576454Z","iopub.execute_input":"2025-04-25T19:42:27.576839Z","iopub.status.idle":"2025-04-25T19:43:18.059282Z","shell.execute_reply.started":"2025-04-25T19:42:27.576812Z","shell.execute_reply":"2025-04-25T19:43:18.058502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rush_hour_counts = my_df.groupby('Is_Rush_Hour_Weekday').size().reset_index(name='Accident_Count')\n\n# Map 0 and 1 to more readable labels\nrush_hour_counts['Label'] = rush_hour_counts['Is_Rush_Hour_Weekday'].map({0: 'Not Rush Hour (Weekday)', 1: 'Rush Hour (Weekday)'})\n\n# Plot\nplt.figure(figsize=(8, 5))\nsns.barplot(data=rush_hour_counts, x='Label', y='Accident_Count', palette='viridis')\n\nplt.title('Number of Accidents During Rush Hour vs Non-Rush Hour on Weekdays')\nplt.ylabel('Accident Count')\nplt.xlabel('')\nplt.tight_layout()\nplt.show()\n\ndaily_stats = my_df.groupby('Date').agg({\n    'Is_Rush_Hour_Weekday': 'mean',  # average rush hour indicator for the day\n    'ID': 'count'  # assuming 'ID' is the unique identifier for each accident\n}).rename(columns={'ID': 'Accident_Count'})\n\ncorrelation = daily_stats['Is_Rush_Hour_Weekday'].corr(daily_stats['Accident_Count'])\nprint(f\"Correlation between Is_Rush_Hour_Weekday and daily accident count: {correlation:.4f}\")\n\ndaily_stats = my_df.groupby('Date').agg({\n    'Is_Peak_Hour': 'mean',  # average rush hour indicator for the day\n    'ID': 'count'  # assuming 'ID' is the unique identifier for each accident\n}).rename(columns={'ID': 'Accident_Count'})\n\ncorrelation = daily_stats['Is_Peak_Hour'].corr(daily_stats['Accident_Count'])\nprint(f\"Correlation between Is_Rush_Hour_Weekday and daily accident count: {correlation:.4f}\")\n\nrisk_level_map = {'Low': 0, 'Medium': 1, 'High': 2}\nmy_df['Hour_Risk_Score'] = my_df['Hour_Risk_Level'].map(risk_level_map)\n\n# Step 2: Group by date and aggregate on the numeric score column\ndaily_stats = my_df.groupby('Date').agg({\n    'Hour_Risk_Score': 'mean',      # Now using the numeric column!\n    'ID': 'count'                   # Count of accidents per day\n}).rename(columns={\n    'Hour_Risk_Score': 'Avg_Hour_Risk_Score',\n    'ID': 'Accident_Count'\n})\n\n# Step 3: Calculate correlation\ncorrelation = daily_stats['Avg_Hour_Risk_Score'].corr(daily_stats['Accident_Count'])\nprint(f\"Correlation between Hour Risk Score and daily accident count: {correlation:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T19:48:47.583227Z","iopub.execute_input":"2025-04-25T19:48:47.583566Z","iopub.status.idle":"2025-04-25T19:48:48.889633Z","shell.execute_reply.started":"2025-04-25T19:48:47.583541Z","shell.execute_reply":"2025-04-25T19:48:48.888602Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hourly_stats = my_df.groupby('Hour').agg({\n    'Hour_Risk_Score': 'mean',  # Average risk score per hour\n}).reset_index()\n\n# If you need to count accidents, you can use .size() instead of 'Accident_Count'\nhourly_stats['Accident_Count'] = my_df.groupby('Hour').size().values\nprint(hourly_stats)\n\n# Assuming hourly_stats is now correctly defined\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x=hourly_stats['Hour_Risk_Score'], y=hourly_stats['Accident_Count'], hue=hourly_stats['Hour'])\nplt.title('Scatter Plot of Hour Risk Score vs. Accident Count')\nplt.xlabel('Hour Risk Score')\nplt.ylabel('Accident Count')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T20:01:02.901559Z","iopub.execute_input":"2025-04-25T20:01:02.901900Z","iopub.status.idle":"2025-04-25T20:01:03.458904Z","shell.execute_reply.started":"2025-04-25T20:01:02.901878Z","shell.execute_reply":"2025-04-25T20:01:03.457935Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I might expect more accidents during rush hours due to increased traffic volume and congestion. However, the correlation I found might not necessarily mean that rush hour leads to fewer accidents. There are several reasons why this might be happening:\n During rush hours, traffic is often slower, which might reduce the likelihood of certain types    of accidents (e.g., high-speed collisions).\n\n Traffic management and signaling are often optimized to prevent accidents during peak hours.\n During rush hour, drivers may drive more cautiously due to heavy traffic, lower speeds, and   higher awareness of the risk of accidents.","metadata":{}},{"cell_type":"code","source":"rush_hour_counts = my_df.groupby('Is_Rush_Hour_Weekend').size().reset_index(name='Accident_Count')\n\n# Map 0 and 1 to more readable labels\nrush_hour_counts['Label'] = rush_hour_counts['Is_Rush_Hour_Weekend'].map({0: 'Not Rush Hour (Weekend)', 1: 'Rush Hour (Weekend)'})\n\n# Plot\nplt.figure(figsize=(8, 5))\nsns.barplot(data=rush_hour_counts, x='Label', y='Accident_Count', palette='viridis')\n\nplt.title('Number of Accidents During Rush Hour vs Non-Rush Hour on Weekdays')\nplt.ylabel('Accident Count')\nplt.xlabel('')\nplt.tight_layout()\nplt.show()\n\ndaily_stats = my_df.groupby('Date').agg({\n    'Is_Rush_Hour_Weekend': 'mean',  # average rush hour indicator for the day\n    'ID': 'count'  # assuming 'ID' is the unique identifier for each accident\n}).rename(columns={'ID': 'Accident_Count'})\n\ncorrelation = daily_stats['Is_Rush_Hour_Weekend'].corr(daily_stats['Accident_Count'])\nprint(daily_stats[['Is_Rush_Hour_Weekend', 'Accident_Count']].isnull().sum())\nprint(f\"Correlation between Is_Rush_Hour_Weekday and daily accident count: {correlation:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T19:05:33.555473Z","iopub.execute_input":"2025-04-25T19:05:33.555850Z","iopub.status.idle":"2025-04-25T19:05:34.149422Z","shell.execute_reply.started":"2025-04-25T19:05:33.555825Z","shell.execute_reply":"2025-04-25T19:05:34.148349Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Filter for weekends (Is_Weekend is True)\nweekend_data = my_df[my_df['Is_Weekend'] == True]\n\n# Group by Hour and count accidents\naccidents_by_hour_weekend = weekend_data.groupby('Hour').size()\n\n# Plot the results\nplt.figure(figsize=(10, 6))\naccidents_by_hour_weekend.plot(kind='bar', color='skyblue')\nplt.title('Most Common Hours for Accidents on Weekends')\nplt.xlabel('Hour of the Day')\nplt.ylabel('Number of Accidents')\nplt.xticks(rotation=0)  # To keep the x-axis labels horizontal\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\npeak_hours = accidents_by_hour_weekend.sort_values(ascending=False).head(12)  # Top 5 hours with the most accidents\nprint(\"Hours with the most accidents:\")\nprint(peak_hours)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T19:36:11.777174Z","iopub.execute_input":"2025-04-25T19:36:11.777515Z","iopub.status.idle":"2025-04-25T19:36:12.846354Z","shell.execute_reply.started":"2025-04-25T19:36:11.777491Z","shell.execute_reply":"2025-04-25T19:36:12.845099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Filter for weekdays (Is_Weekend is False)\nweekday_data = my_df[my_df['Is_Weekend'] == False]\n\n# Group by Hour and count accidents\naccidents_by_hour_weekday = weekday_data.groupby('Hour').size()\n\n# Plot the results\nplt.figure(figsize=(10, 6))\naccidents_by_hour_weekday.plot(kind='bar', color='salmon')\nplt.title('Most Common Hours for Accidents on Weekdays')\nplt.xlabel('Hour of the Day')\nplt.ylabel('Number of Accidents')\nplt.xticks(rotation=0)  # To keep the x-axis labels horizontal\nplt.grid(axis='y', linestyle='--', alpha=0.7)\nplt.show()\n\npeak_hours = accidents_by_hour.sort_values(ascending=False).head(24)  # Top 5 hours with the most accidents\nprint(\"WeekDay Hours with the most accidents:\")\nprint(peak_hours)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T19:37:39.078510Z","iopub.execute_input":"2025-04-25T19:37:39.078864Z","iopub.status.idle":"2025-04-25T19:37:42.182801Z","shell.execute_reply.started":"2025-04-25T19:37:39.078839Z","shell.execute_reply":"2025-04-25T19:37:42.181531Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"month_dummies = pd.get_dummies(my_df['Month'], prefix='Month').astype(int)\nmy_df = pd.concat([my_df, month_dummies], axis=1)\n\nmy_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T11:57:57.896309Z","iopub.execute_input":"2025-04-25T11:57:57.897516Z","iopub.status.idle":"2025-04-25T11:58:03.228913Z","shell.execute_reply.started":"2025-04-25T11:57:57.897439Z","shell.execute_reply":"2025-04-25T11:58:03.227779Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <a id=\"p2\"></a>\n\n# 4. Group by date to aggregate\n","metadata":{"jp-MarkdownHeadingCollapsed":true}},{"cell_type":"code","source":"\n# Group by date to aggregate\ndaily_df =my_df.groupby('date').agg(\n    accident_count=('ID', 'count'),\n    day_of_week=('day_of_week', 'first'),\n    month=('month', 'first'),\n    is_weekend=('is_weekend', 'first'),\n    is_night=('is_night', 'mean'),\n    traffic_signal_rate=('Traffic_Signal', 'mean'),\n    station_rate=('Station', 'mean'),\n    severity_avg=('Severity', 'mean'),\n   # distance_avg=('Distance(mi)', 'mean')\n   # source_diversity=('Source', pd.Series.nunique)\n).reset_index()\n\ndaily_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T11:16:57.063519Z","iopub.status.idle":"2025-04-25T11:16:57.063943Z","shell.execute_reply.started":"2025-04-25T11:16:57.063742Z","shell.execute_reply":"2025-04-25T11:16:57.063760Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### <a id=\"p2\"></a>\n\n# 4.Model Training","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n# Features and Target\nX = daily_df.drop(columns=['date', 'accident_count'])\ny = daily_df['accident_count']\n\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Evaluate\nr2 = model.score(X_test, y_test)\nprint(\"R-squared:\", r2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T11:16:57.065243Z","iopub.status.idle":"2025-04-25T11:16:57.065692Z","shell.execute_reply.started":"2025-04-25T11:16:57.065453Z","shell.execute_reply":"2025-04-25T11:16:57.065470Z"}},"outputs":[],"execution_count":null}]}